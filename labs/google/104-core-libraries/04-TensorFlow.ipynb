{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "\n",
    "    ## Captains Tensorflow and Keras Journey\n",
    "\n",
    "TensorFlow Learning:https://www.tensorflow.org/\n",
    "\n",
    "TensorFlow Glossary:https://developers.google.com/machine-learning/glossary#tensorflow\n",
    "\n",
    "Keras Learning: https://keras.io/\n",
    "\n",
    "Keras Glossary:https://developers.google.com/machine-learning/glossary#keras\n",
    "\n",
    "Now here is my understanding of TensorFlow And Keras:"
   ],
   "id": "e58a21f97de54af9"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-28T21:49:00.310486Z",
     "start_time": "2024-12-28T21:49:00.304975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T21:49:00.326785Z",
     "start_time": "2024-12-28T21:49:00.322206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a tensor which is an array\n",
    "tensor = tf.constant([[1, 2], [3, 4]])\n",
    "print(tensor)\n"
   ],
   "id": "e7b0be8cdf39e0c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T21:49:00.368392Z",
     "start_time": "2024-12-28T21:49:00.358168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# tensor math and manipulation\n",
    "a = tf.constant([[1, 2], [3, 4]])\n",
    "b = tf.constant([[5, 6], [7, 8]])\n",
    "\n",
    "\n",
    "c = tf.add(a, b)\n",
    "print(c)\n",
    "d = tf.multiply(a, b)\n",
    "print(d)\n",
    "e = tf.subtract(a, b)\n",
    "print(e)\n",
    "f = tf.divide(a, b)\n",
    "print(f)"
   ],
   "id": "a1c7744a571278ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 6  8]\n",
      " [10 12]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 5 12]\n",
      " [21 32]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[-4 -4]\n",
      " [-4 -4]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[0.2        0.33333333]\n",
      " [0.42857143 0.5       ]], shape=(2, 2), dtype=float64)\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T21:49:00.414944Z",
     "start_time": "2024-12-28T21:49:00.410605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# manipulating tensor attributes\n",
    "print(tensor.shape)  # Shape of the tensor\n",
    "print(tensor.dtype)  # Data type of the tensor\n",
    "\n"
   ],
   "id": "37e380e76990a5ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n",
      "<dtype: 'int32'>\n"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T21:49:00.448517Z",
     "start_time": "2024-12-28T21:49:00.439469Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# using tensorflow functions\n",
    "zeros = tf.zeros([3, 3])  # 3x3 matrix of zeros\n",
    "ones = tf.ones([3, 3])    # 3x3 matrix of ones\n",
    "random = tf.random.normal([3, 3], mean=2, stddev=1)  # Random normal distribution\n",
    "print(random)\n"
   ],
   "id": "720f2f31ba4df6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2.0429883 2.380245  1.9222012]\n",
      " [1.6918265 2.0233934 1.6603146]\n",
      " [2.0601664 2.623907  3.745914 ]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T21:49:00.482131Z",
     "start_time": "2024-12-28T21:49:00.476452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# converting numpy to tensorflow\n",
    "import numpy as np\n",
    "array = np.array([1, 2, 3])\n",
    "tensor = tf.convert_to_tensor(array)\n",
    "print(tensor)\n"
   ],
   "id": "b2970e84f385242b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2 3], shape=(3,), dtype=int64)\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T21:49:00.533750Z",
     "start_time": "2024-12-28T21:49:00.525965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# tensorflow variables\n",
    "var = tf.Variable([1.0, 2.0, 3.0])\n",
    "print(var)\n",
    "var.assign([4.0, 5.0, 6.0])  # Assign new values\n",
    "print(var)\n"
   ],
   "id": "a1774227a6da84d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([1., 2., 3.], dtype=float32)>\n",
      "<tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([4., 5., 6.], dtype=float32)>\n"
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T21:49:00.577366Z",
     "start_time": "2024-12-28T21:49:00.571602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Gradient Computation with Autograd using tf.GradientTape\n",
    "x = tf.Variable(3.0)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    y = x ** 2\n",
    "\n",
    "# Compute the gradient of y with respect to x\n",
    "grad = tape.gradient(y, x)\n",
    "print(grad)\n"
   ],
   "id": "1438b19a6b66a15d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T21:49:00.652974Z",
     "start_time": "2024-12-28T21:49:00.618451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# How to Define a Model\n",
    "# Build a simple model\n",
    "model = Sequential([\n",
    "    Dense(10, activation='relu', input_shape=(5,)),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "model.summary()\n"
   ],
   "id": "990e511f745c296a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_5\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_10 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m10\u001B[0m)             │            \u001B[38;5;34m60\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │            \u001B[38;5;34m11\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m71\u001B[0m (284.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">71</span> (284.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m71\u001B[0m (284.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">71</span> (284.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T21:49:00.689746Z",
     "start_time": "2024-12-28T21:49:00.680479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',  # Mean squared error\n",
    "              metrics=['mae'])  # Mean absolute error\n"
   ],
   "id": "ad12db63622fe2ff",
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T21:49:01.891517Z",
     "start_time": "2024-12-28T21:49:00.707485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train the model\n",
    "import numpy as np\n",
    "\n",
    "# Generate dummy data\n",
    "x_train = np.random.rand(100, 5)  # 100 samples, 5 features each\n",
    "y_train = np.random.rand(100, 1)  # 100 labels\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32)\n"
   ],
   "id": "7d788705830fd16f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - loss: 1.5193 - mae: 1.1777  \n",
      "Epoch 2/10\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 1.4192 - mae: 1.1386 \n",
      "Epoch 3/10\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 1.3041 - mae: 1.0854 \n",
      "Epoch 4/10\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 1.2300 - mae: 1.0578 \n",
      "Epoch 5/10\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 1.1327 - mae: 1.0039 \n",
      "Epoch 6/10\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 1.0033 - mae: 0.9453 \n",
      "Epoch 7/10\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.9341 - mae: 0.9071 \n",
      "Epoch 8/10\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.8570 - mae: 0.8657 \n",
      "Epoch 9/10\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.8156 - mae: 0.8387 \n",
      "Epoch 10/10\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.7216 - mae: 0.7848 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17ac88a40>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T21:50:16.367079Z",
     "start_time": "2024-12-28T21:50:15.883799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "    # TensorFlow Datasets\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Load a dataset\n",
    "dataset, info = tfds.load('mnist', as_supervised=True, with_info=True)\n",
    "print(info)\n"
   ],
   "id": "222bbf7e7a573780",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Descriptors cannot be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[92], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# TensorFlow Datasets\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow_datasets\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Load a dataset\u001B[39;00m\n\u001B[1;32m      5\u001B[0m dataset, info \u001B[38;5;241m=\u001B[39m load(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmnist\u001B[39m\u001B[38;5;124m'\u001B[39m, as_supervised\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, with_info\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/miniforge3/envs/ml/lib/python3.12/site-packages/tensorflow_datasets/__init__.py:43\u001B[0m\n\u001B[1;32m     41\u001B[0m _TIMESTAMP_IMPORT_STARTS \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mabsl\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m logging\n\u001B[0;32m---> 43\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow_datasets\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlogging\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01m_tfds_logging\u001B[39;00m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow_datasets\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlogging\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m call_metadata \u001B[38;5;28;01mas\u001B[39;00m _call_metadata\n\u001B[1;32m     46\u001B[0m _metadata \u001B[38;5;241m=\u001B[39m _call_metadata\u001B[38;5;241m.\u001B[39mCallMetadata()\n",
      "File \u001B[0;32m~/miniforge3/envs/ml/lib/python3.12/site-packages/tensorflow_datasets/core/__init__.py:22\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# Allow to use `tfds.core.Path` in dataset implementation which seems more\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# natural than having to import a third party module.\u001B[39;00m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01metils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mepath\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Path\n\u001B[0;32m---> 22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow_datasets\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m community\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow_datasets\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdataset_builder\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BeamBasedBuilder\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow_datasets\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdataset_builder\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BuilderConfig\n",
      "File \u001B[0;32m~/miniforge3/envs/ml/lib/python3.12/site-packages/tensorflow_datasets/core/community/__init__.py:18\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# coding=utf-8\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# Copyright 2022 The TensorFlow Datasets Authors.\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# See the License for the specific language governing permissions and\u001B[39;00m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# limitations under the License.\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;124;03m\"\"\"Community dataset API.\"\"\"\u001B[39;00m\n\u001B[0;32m---> 18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow_datasets\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommunity\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mhuggingface_wrapper\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m mock_builtin_to_use_gfile\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow_datasets\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommunity\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mhuggingface_wrapper\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m mock_huggingface_import\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow_datasets\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommunity\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mload\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m builder_cls_from_module\n",
      "File \u001B[0;32m~/miniforge3/envs/ml/lib/python3.12/site-packages/tensorflow_datasets/core/community/huggingface_wrapper.py:31\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01munittest\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m mock\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01metils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m epath\n\u001B[0;32m---> 31\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow_datasets\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dataset_builder\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow_datasets\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dataset_info\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow_datasets\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m download\n",
      "File \u001B[0;32m~/miniforge3/envs/ml/lib/python3.12/site-packages/tensorflow_datasets/core/dataset_builder.py:33\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01metils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m epath\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow_datasets\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m constants\n\u001B[0;32m---> 33\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow_datasets\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dataset_info\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow_datasets\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dataset_metadata\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow_datasets\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m decode\n",
      "File \u001B[0;32m~/miniforge3/envs/ml/lib/python3.12/site-packages/tensorflow_datasets/core/dataset_info.py:49\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow_datasets\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m lazy_imports_lib\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow_datasets\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m naming\n\u001B[0;32m---> 49\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow_datasets\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m splits \u001B[38;5;28;01mas\u001B[39;00m splits_lib\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow_datasets\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m utils\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow_datasets\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfeatures\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m feature \u001B[38;5;28;01mas\u001B[39;00m feature_lib\n",
      "File \u001B[0;32m~/miniforge3/envs/ml/lib/python3.12/site-packages/tensorflow_datasets/core/splits.py:34\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01metils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m epath\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow_datasets\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m naming\n\u001B[0;32m---> 34\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow_datasets\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m proto \u001B[38;5;28;01mas\u001B[39;00m proto_lib\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow_datasets\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m units\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow_datasets\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m utils\n",
      "File \u001B[0;32m~/miniforge3/envs/ml/lib/python3.12/site-packages/tensorflow_datasets/core/proto/__init__.py:18\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# coding=utf-8\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# Copyright 2022 The TensorFlow Datasets Authors.\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# See the License for the specific language governing permissions and\u001B[39;00m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# limitations under the License.\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;124;03m\"\"\"Public API of the proto package.\"\"\"\u001B[39;00m\n\u001B[0;32m---> 18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow_datasets\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mproto\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dataset_info_generated_pb2 \u001B[38;5;28;01mas\u001B[39;00m dataset_info_pb2  \u001B[38;5;66;03m# pylint: disable=line-too-long\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow_datasets\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mproto\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m feature_generated_pb2 \u001B[38;5;28;01mas\u001B[39;00m feature_pb2  \u001B[38;5;66;03m# pylint: disable=line-too-long\u001B[39;00m\n\u001B[1;32m     21\u001B[0m SplitInfo \u001B[38;5;241m=\u001B[39m dataset_info_pb2\u001B[38;5;241m.\u001B[39mSplitInfo\n",
      "File \u001B[0;32m~/miniforge3/envs/ml/lib/python3.12/site-packages/tensorflow_datasets/core/proto/dataset_info_generated_pb2.py:30\u001B[0m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;66;03m# @@protoc_insertion_point(imports)\u001B[39;00m\n\u001B[1;32m     28\u001B[0m _sym_db \u001B[38;5;241m=\u001B[39m _symbol_database\u001B[38;5;241m.\u001B[39mDefault()\n\u001B[0;32m---> 30\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow_datasets\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mproto\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m feature_generated_pb2 \u001B[38;5;28;01mas\u001B[39;00m feature__pb2\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow_metadata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mproto\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv0\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m schema_pb2 \u001B[38;5;28;01mas\u001B[39;00m tensorflow__metadata_dot_proto_dot_v0_dot_schema__pb2\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow_metadata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mproto\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv0\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m statistics_pb2 \u001B[38;5;28;01mas\u001B[39;00m tensorflow__metadata_dot_proto_dot_v0_dot_statistics__pb2\n",
      "File \u001B[0;32m~/miniforge3/envs/ml/lib/python3.12/site-packages/tensorflow_datasets/core/proto/feature_generated_pb2.py:94\u001B[0m\n\u001B[1;32m     28\u001B[0m _sym_db \u001B[38;5;241m=\u001B[39m _symbol_database\u001B[38;5;241m.\u001B[39mDefault()\n\u001B[1;32m     30\u001B[0m DESCRIPTOR \u001B[38;5;241m=\u001B[39m _descriptor\u001B[38;5;241m.\u001B[39mFileDescriptor(\n\u001B[1;32m     31\u001B[0m     name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfeature.proto\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     32\u001B[0m     package\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtensorflow_datasets\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     84\u001B[0m     ),\n\u001B[1;32m     85\u001B[0m )\n\u001B[1;32m     87\u001B[0m _FEATURESDICT_FEATURESENTRY \u001B[38;5;241m=\u001B[39m _descriptor\u001B[38;5;241m.\u001B[39mDescriptor(\n\u001B[1;32m     88\u001B[0m     name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFeaturesEntry\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     89\u001B[0m     full_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtensorflow_datasets.FeaturesDict.FeaturesEntry\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     90\u001B[0m     filename\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     91\u001B[0m     file\u001B[38;5;241m=\u001B[39mDESCRIPTOR,\n\u001B[1;32m     92\u001B[0m     containing_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     93\u001B[0m     fields\u001B[38;5;241m=\u001B[39m[\n\u001B[0;32m---> 94\u001B[0m         \u001B[43m_descriptor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mFieldDescriptor\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     95\u001B[0m \u001B[43m            \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mkey\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     96\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfull_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtensorflow_datasets.FeaturesDict.FeaturesEntry.key\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     97\u001B[0m \u001B[43m            \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     98\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnumber\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     99\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m9\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    100\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcpp_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m9\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    101\u001B[0m \u001B[43m            \u001B[49m\u001B[43mlabel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    102\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhas_default_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    103\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdefault_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43mb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    104\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmessage_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    105\u001B[0m \u001B[43m            \u001B[49m\u001B[43menum_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    106\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcontaining_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    107\u001B[0m \u001B[43m            \u001B[49m\u001B[43mis_extension\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    108\u001B[0m \u001B[43m            \u001B[49m\u001B[43mextension_scope\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    109\u001B[0m \u001B[43m            \u001B[49m\u001B[43mserialized_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    110\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfile\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mDESCRIPTOR\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    111\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m    112\u001B[0m         _descriptor\u001B[38;5;241m.\u001B[39mFieldDescriptor(\n\u001B[1;32m    113\u001B[0m             name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalue\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m    114\u001B[0m             full_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtensorflow_datasets.FeaturesDict.FeaturesEntry.value\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m    115\u001B[0m             index\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m    116\u001B[0m             number\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[1;32m    117\u001B[0m             \u001B[38;5;28mtype\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m11\u001B[39m,\n\u001B[1;32m    118\u001B[0m             cpp_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m,\n\u001B[1;32m    119\u001B[0m             label\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m    120\u001B[0m             has_default_value\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    121\u001B[0m             default_value\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    122\u001B[0m             message_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    123\u001B[0m             enum_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    124\u001B[0m             containing_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    125\u001B[0m             is_extension\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    126\u001B[0m             extension_scope\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    127\u001B[0m             serialized_options\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    128\u001B[0m             file\u001B[38;5;241m=\u001B[39mDESCRIPTOR,\n\u001B[1;32m    129\u001B[0m         ),\n\u001B[1;32m    130\u001B[0m     ],\n\u001B[1;32m    131\u001B[0m     extensions\u001B[38;5;241m=\u001B[39m[],\n\u001B[1;32m    132\u001B[0m     nested_types\u001B[38;5;241m=\u001B[39m[],\n\u001B[1;32m    133\u001B[0m     enum_types\u001B[38;5;241m=\u001B[39m[],\n\u001B[1;32m    134\u001B[0m     serialized_options\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m8\u001B[39m\u001B[38;5;130;01m\\001\u001B[39;00m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m    135\u001B[0m     is_extendable\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    136\u001B[0m     syntax\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mproto3\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m    137\u001B[0m     extension_ranges\u001B[38;5;241m=\u001B[39m[],\n\u001B[1;32m    138\u001B[0m     oneofs\u001B[38;5;241m=\u001B[39m[],\n\u001B[1;32m    139\u001B[0m     serialized_start\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m122\u001B[39m,\n\u001B[1;32m    140\u001B[0m     serialized_end\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m199\u001B[39m,\n\u001B[1;32m    141\u001B[0m )\n\u001B[1;32m    143\u001B[0m _FEATURESDICT \u001B[38;5;241m=\u001B[39m _descriptor\u001B[38;5;241m.\u001B[39mDescriptor(\n\u001B[1;32m    144\u001B[0m     name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFeaturesDict\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m    145\u001B[0m     full_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtensorflow_datasets.FeaturesDict\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    180\u001B[0m     serialized_end\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m199\u001B[39m,\n\u001B[1;32m    181\u001B[0m )\n\u001B[1;32m    183\u001B[0m _FEATURE \u001B[38;5;241m=\u001B[39m _descriptor\u001B[38;5;241m.\u001B[39mDescriptor(\n\u001B[1;32m    184\u001B[0m     name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFeature\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m    185\u001B[0m     full_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtensorflow_datasets.Feature\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    478\u001B[0m     serialized_end\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m952\u001B[39m,\n\u001B[1;32m    479\u001B[0m )\n",
      "File \u001B[0;32m~/miniforge3/envs/ml/lib/python3.12/site-packages/google/protobuf/descriptor.py:621\u001B[0m, in \u001B[0;36mFieldDescriptor.__new__\u001B[0;34m(cls, name, full_name, index, number, type, cpp_type, label, default_value, message_type, enum_type, containing_type, is_extension, extension_scope, options, serialized_options, has_default_value, containing_oneof, json_name, file, create_key)\u001B[0m\n\u001B[1;32m    615\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__new__\u001B[39m(\u001B[38;5;28mcls\u001B[39m, name, full_name, index, number, \u001B[38;5;28mtype\u001B[39m, cpp_type, label,\n\u001B[1;32m    616\u001B[0m             default_value, message_type, enum_type, containing_type,\n\u001B[1;32m    617\u001B[0m             is_extension, extension_scope, options\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    618\u001B[0m             serialized_options\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    619\u001B[0m             has_default_value\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, containing_oneof\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, json_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    620\u001B[0m             file\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, create_key\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):  \u001B[38;5;66;03m# pylint: disable=redefined-builtin\u001B[39;00m\n\u001B[0;32m--> 621\u001B[0m   \u001B[43m_message\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mMessage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_CheckCalledFromGeneratedFile\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    622\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m is_extension:\n\u001B[1;32m    623\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _message\u001B[38;5;241m.\u001B[39mdefault_pool\u001B[38;5;241m.\u001B[39mFindExtensionByName(full_name)\n",
      "\u001B[0;31mTypeError\u001B[0m: Descriptors cannot be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates"
     ]
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T21:49:39.556057Z",
     "start_time": "2024-12-28T21:49:39.534411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess(image, label):\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # Normalize to [0, 1]\n",
    "    return image, label\n",
    "\n",
    "dataset = dataset.map(preprocess).batch(32)\n"
   ],
   "id": "16c9acd3b2f49085",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[91], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m     image \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mcast(image, tf\u001B[38;5;241m.\u001B[39mfloat32) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m255.0\u001B[39m  \u001B[38;5;66;03m# Normalize to [0, 1]\u001B[39;00m\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m image, label\n\u001B[0;32m----> 5\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[43mdataset\u001B[49m\u001B[38;5;241m.\u001B[39mmap(preprocess)\u001B[38;5;241m.\u001B[39mbatch(\u001B[38;5;241m32\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "execution_count": 91
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
